################################################################
# BOT
################################################################
bot.mmost.enabled=true
%test.bot.mmost.enabled=false
bot.mmost.serverUrl=http://localhost:8065
bot.mmost.login=ava@ava.co
bot.mmost.password=AvaAva123!
bot.mmost.home=town-square
bot.mmost.team=test
bot.mmost.pollingInterval=8
quarkus.scheduler.start-mode=forced
quarkus.swagger-ui.always-include=false

################################################################
# HTTP
################################################################
quarkus.rest-client.oai-api.url=https://api.openai.com/v1
quarkus.rest-client.oai-api.connect-timeout=5000
quarkus.rest-client.oai-api.read-timeout=20000
#quarkus.rest-client.oai-api.user-agent="xxxx"
#quarkus.jackson.fail-on-unknown-properties=true
#mmost quarkus.naming.enable-jndi=true

################################################################
# OpenAI
################################################################
CLIENT_OPENAI_SECRET_KEY=weeeeee
client.oai.secret-key=Bearer ${CLIENT_OPENAI_SECRET_KEY:weeeeee}
client.oai.model=gpt-3.5-turbo
# for massive 32k chat : client.oai.model=gpt-4-32k-0314
#code-davinci-002=codex
#1/10th the cost of text-davinci-003
#/chat/completions:3.5 /completions:dv003
#client.oai.models=code-davinci-002,code-cushman-001
client.oai.temperature=low (not much creative)
#use moderation classifier scores + flagged (true != policy)
#dv : maxreq 8000tokens, cm (faster, RT) : 2048 tokens
#https://beta.openai.com/docs/guides/production-best-practices/example-procedure-for-evaluating-a-gpt-3-based-system

################################################################
# Costs
################################################################
#A helpful rule of thumb is that one token generally corresponds to ~4 characters of text for common English text. This translates to roughly ¾ of a word (so 100 tokens ~= 75 words).

client.oai.tokenizer=https://platform.openai.com/tokenizer

################################################################
# local inference
################################################################
# HuggingFace
################################################################
# BLOOM
# see https://huggingface.co/bigscience/bloomz-7b1
# see https://github.com/NouamaneTazi/bloomz.cpp
# !!! CONFIGURE AND CHANGE THESE TO YOUR OWN ABSOLUTE PATHS !!!
hf.bloom.executor=/home/lperez/Bureau/work/lpe/bloomz.cpp/main
hf.bloom.executorModelGgml=/home/lperez/Bureau/work/lpe/bloomz.cpp/models/ggml-model-bloomz-7b1-f16-q4_0.bin
hf.bloom.executorThreads=8
#hf.bloom.model=bigscience/bloomz-7b1
hf.api.secret-key=foo

alpaca.executor=/home/lperez/Bureau/work/lpe/alpaca.cpp/main
llama.executor=/home/lperez/Bureau/work/lpe/llama.cpp/main
llama.executorModelGgml=/home/lperez/Bureau/work/lpe/llama.cpp/models/ggml-model-q4.bin
# might be of interest for research : https://github.com/facebookresearch/llama/pull/73
#sf codegen : nl=pile,multi=nl + multiple,mono=multi+python

################################################################
# LOGS
################################################################
quarkus.log.console.format=%d{HH:mm:ss} %-5p [%c{2.}:%L] (%t) %s%e%n
quarkus.console.color=true
quarkus.log.file.format=%d{HH:mm:ss} %-5p [%c{2.}:%L] (%t) %s%e%n
quarkus.log.file.enable=true
quarkus.log.category."fr.ava".level=DEBUG
quarkus.log.category."net.bis5.mattermost".level=DEBUG
#quarkus.log.category."org.glassfish.jersey".level=DEBUG
quarkus.log.category."org.apache.http.wire".level=DEBUG
#TODO don't use the reactive client until mattermost4j has resteasy support
#quarkus.log.category."org.jboss.resteasy.reactive.client.logging".level=DEBUG
quarkus.rest-client.logging.scope=request-response
#quarkus.rest-client.logging.body-limit=1024

################################################################
# DATABASE
################################################################
quarkus.datasource.db-kind=postgresql
quarkus.datasource.username=postgres
quarkus.datasource.password=postgres
quarkus.datasource.jdbc.url=jdbc:postgresql://localhost:5432/avadb
# drop and create the database at startup (use `update` to only update the schema)
quarkus.hibernate-orm.database.generation=drop-and-create
#quarkus.hibernate-orm.database.generation=update
%prod%.quarkus.hibernate-orm.database.generation=none
